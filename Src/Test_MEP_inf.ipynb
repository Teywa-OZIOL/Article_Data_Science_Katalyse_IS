{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model pipeline_processing\n",
      "Registering model modelML2\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model1 = Model.register(model_path=\"./pipeline_processing.pkl\",\n",
    "                    model_name=\"pipeline_processing\",\n",
    "                    workspace=ws)\n",
    "\n",
    "model2 = Model.register(model_path=\"./modelML2.pkl\",\n",
    "                    model_name=\"modelML2\",\n",
    "                    workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_name = './'\n",
    "script_file = os.path.join(folder_name,\"score_script.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./score_script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "import json\n",
    "import pickle\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global model_pipe\n",
    "    global model_xgb\n",
    "        \n",
    "    model_path1 = Model.get_model_path('pipeline_processing')\n",
    "    model_pipe = joblib.load(model_path1)\n",
    "    model_path2 = Model.get_model_path('modelML2')\n",
    "    model_xgb = pickle.load(open(model_path2, \"rb\"))\n",
    "\n",
    "\n",
    "def run(raw_data):\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    df = pd.DataFrame(data ,columns=[\"CreditScore\", \"Geography\", \"Gender\", \"Age\", \"Tenure\", \"Balance\", \"NumOfProducts\", \"HasCrCard\", \"IsActiveMember\", \"EstimatedSalary\"])  \n",
    "    predictions = model_xgb.predict_proba(model_pipe.transform(df))\n",
    "    return json.dumps(predictions.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package('scikit-learn=0.22.1')\n",
    "myenv.add_conda_package('xgboost')\n",
    "\n",
    "env_file = os.path.join(folder_name,\"scoring_env.yml\")\n",
    "with open(env_file,\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running..................................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core import Model\n",
    "\n",
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                   entry_script=script_file,\n",
    "                                   conda_file=env_file)\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "\n",
    "service_name = \"first-scoring-service\"\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model1, model2], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy\n",
      "2021-02-15T13:50:56,857416900+00:00 - gunicorn/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_82ee99abb7a87bcb27f9ff905adf82e6/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_82ee99abb7a87bcb27f9ff905adf82e6/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_82ee99abb7a87bcb27f9ff905adf82e6/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_82ee99abb7a87bcb27f9ff905adf82e6/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_82ee99abb7a87bcb27f9ff905adf82e6/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "2021-02-15T13:50:56,859576925+00:00 - nginx/run \n",
      "2021-02-15T13:50:56,868849264+00:00 - iot-server/run \n",
      "2021-02-15T13:50:56,881331489+00:00 - rsyslog/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-02-15T13:50:57,101465166+00:00 - iot-server/finish 1 0\n",
      "2021-02-15T13:50:57,110201673+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (9)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 38\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-02-15 13:50:59,050 | root | INFO | Starting up app insights client\n",
      "2021-02-15 13:50:59,050 | root | INFO | Starting up request id generator\n",
      "2021-02-15 13:50:59,050 | root | INFO | Starting up app insight hooks\n",
      "2021-02-15 13:50:59,050 | root | INFO | Invoking user's init function\n",
      "/azureml-envs/azureml_82ee99abb7a87bcb27f9ff905adf82e6/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator OneHotEncoder from version 0.23.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/azureml-envs/azureml_82ee99abb7a87bcb27f9ff905adf82e6/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.23.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/azureml-envs/azureml_82ee99abb7a87bcb27f9ff905adf82e6/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.23.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/azureml-envs/azureml_82ee99abb7a87bcb27f9ff905adf82e6/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator ColumnTransformer from version 0.23.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "2021-02-15 13:50:59,469 | root | INFO | Users's init has completed successfully\n",
      "2021-02-15 13:50:59,472 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-02-15 13:50:59,472 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-02-15 13:50:59,472 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "2021-02-15 13:51:08,761 | root | INFO | Swagger file not present\n",
      "2021-02-15 13:51:08,761 | root | INFO | 404\n",
      "127.0.0.1 - - [15/Feb/2021:13:51:08 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-02-15 13:51:11,236 | root | INFO | Swagger file not present\n",
      "2021-02-15 13:51:11,237 | root | INFO | 404\n",
      "127.0.0.1 - - [15/Feb/2021:13:51:11 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.state)\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9785522222518921, 0.021447796374559402]]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "x_new = [[596, \"Germany\", \"Male\", 32, 3, 96709.1, 2, 0, 0, 41788.4]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Call the web service, passing the input data (the web service will also accept the data in binary format)\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted class - it'll be the first (and only) one.\n",
    "result = json.loads(predictions)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://8aaf3742-a34f-4abe-8473-be7eb300dda6.francecentral.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "endpoint = service.scoring_uri\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9785522222518921, 0.021447796374559402]]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "x_new = [[596, \"Germany\", \"Male\", 32, 3, 96709.1, 2, 0, 0, 41788.4]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Set the content type\n",
    "headers = { 'Content-Type':'application/json' }\n",
    "\n",
    "predictions = requests.post(endpoint, input_json, headers = headers)\n",
    "predicted_classes = json.loads(predictions.json())\n",
    "\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = ws.webservices['first-scoring-service']\n",
    "service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
